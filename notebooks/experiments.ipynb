{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by the article https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0034928&type=printable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depressive disorder is a serious mood disorder which affects the way you handle daily activities, the way you feel, think and consequently speak. Thefore text is one of the significant objects of psychometric analysis. Itâ€™s careful investigation can help to define whether the author of the text is suffering from a mental disease. Most reaserches when aiming to extract features of depressive text focus on semantic analysis of the text and topic retrieval (Ma et al. 2017). We are attemting to center our attention on the structure of the text connecting this feature to one of the symptoms of depression - reduced brain activity (Zhang et al. 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('PsyHack_RUDN_test.csv', sep='\\t')\n",
    "train_df = pd.read_csv('PsyHack_RUDN_train.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Non-depression    158\n",
       "Depression         63\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.fillna(value=0, inplace=True)\n",
    "test_df.fillna(value=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Nodes', 'Edges', 'ATD', 'LCC', 'LSC', 'L1', 'L2', 'L3', 'Density',\n",
       "       'Diameter', 'ASP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers experimented with in the article:\n",
    "- NB\n",
    "- SVM\n",
    "- DT\n",
    "- MLP\n",
    "- RBF\n",
    "\n",
    "NB gave the best results\n",
    "\n",
    "\"...we trained a naive Bayes (NB) classifier with different subsets of graph measures as inputs. The data were normalized by the number of words in each report, in order to discount the effects of normal inter-individual verbosity differences. Furthermore, the inputs were restricted to data that could be obtained without having to resort to an interpretation of the meaning of the reports, i.e. waking nodes and edges were not employed. Sensitivity, specificity, the area under the receiver operating characteristic curve (AUC) [14] and the kappa statistic [15] were used as metrics of classification quality. Our approach objectively and accurately distinguished schizophrenic from manic reports (Fig. 8), and was comparable to the inter-rater reliability of SCID for the distinction between schizophrenics and controls, but not for the distinction between manics and controls [16], [17]. In contrast, when the scores from the psychometric scales BPRS and PANSS were used as inputs to the classifier, it was possible to distinguish controls from psychotic patients, but not schizophrenics from manics.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.29000000e+02   3.17000000e+02   1.38427948e+00 ...,   6.07140121e-03\n",
      "    1.30000000e+01   2.93695420e+00]\n",
      " [  1.64000000e+02   2.47000000e+02   1.50609756e+00 ...,   9.23986234e-03\n",
      "    1.30000000e+01   4.25347898e+00]\n",
      " [  1.58000000e+02   2.82000000e+02   1.78481013e+00 ...,   1.13682174e-02\n",
      "    8.00000000e+00   2.29557324e+00]\n",
      " ..., \n",
      " [  1.13000000e+02   9.40000000e+01   8.31858407e-01 ...,   7.42730721e-03\n",
      "    1.40000000e+01   1.64077527e+00]\n",
      " [  1.31000000e+02   1.31000000e+02   1.00000000e+00 ...,   7.69230769e-03\n",
      "    1.30000000e+01   1.88873835e+00]\n",
      " [  1.51000000e+02   1.62000000e+02   1.07284768e+00 ...,   7.15231788e-03\n",
      "    1.60000000e+01   1.52928653e+00]]\n"
     ]
    }
   ],
   "source": [
    "train_features=np.array(train_df.values[:, 4:], dtype = np.float64)\n",
    "test_features=np.array(test_df.values[:, 4:], dtype = np.float64)\n",
    "print (train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "#creating labelEncoder\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label=le.fit_transform(train_df.label)\n",
    "test_label = le.fit_transform(test_df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with the same set of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(train_features,train_label)\n",
    "\n",
    "#Predict Output\n",
    "predicted= model.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7263157894736842\n",
      "Precision: 0.76\n",
      "Recall: 0.8769230769230769\n",
      "F1-score: 0.8142857142857143\n",
      "AUC-ROC: 0.6384615384615384\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_label,predicted.argmax(axis=1)))\n",
    "print(\"Precision:\",metrics.precision_score(test_label,predicted.argmax(axis=1)))\n",
    "print(\"Recall:\",metrics.recall_score(test_label,predicted.argmax(axis=1)))\n",
    "print(\"F1-score:\",metrics.f1_score(test_label,predicted.argmax(axis=1)))\n",
    "print(\"AUC-ROC:\",metrics.roc_auc_score(test_label,predicted.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 1337\n",
    "\n",
    "C_array = np.logspace(-3, 3, num=7)\n",
    "gamma_array = np.logspace(-5, 2, num=8)\n",
    "\n",
    "svm_parameters = {\n",
    "      'C': C_array, \n",
    "       'gamma': gamma_array, \n",
    "       'kernel': ['linear']\n",
    "}\n",
    "\n",
    "grid_parameters = {\n",
    "    'scoring': make_scorer(roc_auc_score),\n",
    "    'n_jobs': -1,\n",
    "    'cv': 20,\n",
    "    'iid': True,\n",
    "    'return_train_score': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(random_state=RANDOM_STATE, probability=True)\n",
    "\n",
    "\n",
    "grid_svm = GridSearchCV(\n",
    "    estimator=svm,\n",
    "    param_grid=svm_parameters,\n",
    "    scoring=make_scorer(roc_auc_score),\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    iid=True,\n",
    "    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM ROC AUC score:  0.645919999513453\n"
     ]
    }
   ],
   "source": [
    "grid_svm.fit(train_features,train_label)\n",
    "\n",
    "print('SVM ROC AUC score: ', grid_svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000.0, 'gamma': 1e-05, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(random_state=RANDOM_STATE, probability=True, C =1000.0, gamma = 1e-05, kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=1e-05, kernel='linear',\n",
       "    max_iter=-1, probability=True, random_state=1337, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(train_features,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict Output\n",
    "predicted= svm.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6947368421052632\n",
      "Precision: 0.6914893617021277\n",
      "Recall: 1.0\n",
      "F1-score: 0.8176100628930818\n",
      "AUC-ROC: 0.5166666666666666\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_label,predicted.argmax(axis=1)))\n",
    "print(\"Precision:\",metrics.precision_score(test_label,predicted.argmax(axis=1)))\n",
    "print(\"Recall:\",metrics.recall_score(test_label,predicted.argmax(axis=1)))\n",
    "print(\"F1-score:\",metrics.f1_score(test_label,predicted.argmax(axis=1)))\n",
    "print(\"AUC-ROC:\",metrics.roc_auc_score(test_label,predicted.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 1337\n",
    "\n",
    "C_array = np.logspace(-3, 3, num=7)\n",
    "gamma_array = np.logspace(-5, 2, num=8)\n",
    "\n",
    "svm_parameters = {\n",
    "      'C': C_array, \n",
    "       'gamma': gamma_array, \n",
    "       'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "grid_parameters = {\n",
    "    'scoring': make_scorer(roc_auc_score),\n",
    "    'n_jobs': -1,\n",
    "    'cv': 3,\n",
    "    'iid': True,\n",
    "    'return_train_score': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(random_state=RANDOM_STATE, probability=True)\n",
    "\n",
    "\n",
    "grid_svm = GridSearchCV(\n",
    "    estimator=svm,\n",
    "    param_grid=svm_parameters,\n",
    "    scoring=make_scorer(roc_auc_score),\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    iid=True,\n",
    "    return_train_score=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM ROC AUC score:  0.7534317077411835\n"
     ]
    }
   ],
   "source": [
    "grid_svm.fit(train_features,train_label)\n",
    "\n",
    "print('SVM ROC AUC score: ', grid_svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000.0, 'gamma': 1e-05, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(random_state=RANDOM_STATE, probability=True, C =10.0, gamma = 1e-05, kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=1e-05, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=1337, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(train_features,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict Output\n",
    "predicted= svm.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.7759289505920783\n"
     ]
    }
   ],
   "source": [
    "p = svm.predict_proba(train_features)\n",
    "print(\"AUC-ROC:\",metrics.roc_auc_score(train_label,p.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7473684210526316\n",
      "Precision: 0.7662337662337663\n",
      "Recall: 0.9076923076923077\n",
      "F1-score: 0.8309859154929577\n",
      "AUC-ROC: 0.6538461538461539\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_label,predicted.argmax(axis=1)))\n",
    "print(\"Precision:\",metrics.precision_score(test_label,predicted.argmax(axis=1)))\n",
    "print(\"Recall:\",metrics.recall_score(test_label,predicted.argmax(axis=1)))\n",
    "print(\"F1-score:\",metrics.f1_score(test_label,predicted.argmax(axis=1)))\n",
    "# print(\"AUC-ROC:\",metrics.roc_auc_score(test_label,[predicted[i][1] if e==1 else predicted[i][0] for i, e in enumerate(predicted.argmax(axis=1))]))\n",
    "print(\"AUC-ROC:\",metrics.roc_auc_score(test_label,predicted.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'min_child_weight': [1, 2, 3,4, 5,6, 7,8,9, 10, 15, 20],\n",
    "        'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.5, 2, 5, 10, 15, 20],\n",
    "        'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 20, 25, 30,35]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "folds = 3\n",
    "param_comb = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=skf.split(train_features,train_label), verbose=3, random_state=1001 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x7f0061e97258>,\n",
       "                   error_score=nan,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.02, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=600,\n",
       "                                           n_jobs=1, nthread=1,\n",
       "                                           objective='binary:logist...\n",
       "                                                             0.5, 0.6, 0.7, 0.8,\n",
       "                                                             0.9, 1.0],\n",
       "                                        'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6,\n",
       "                                                  0.7, 0.8, 0.9, 1.0, 1.5, 2, 5,\n",
       "                                                  10, 15, 20],\n",
       "                                        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 15, 20, 25,\n",
       "                                                      30, 35],\n",
       "                                        'min_child_weight': [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10, 15,\n",
       "                                                             20],\n",
       "                                        'subsample': [0.1, 0.2, 0.3, 0.4, 0.5,\n",
       "                                                      0.6, 0.7, 0.8, 0.9,\n",
       "                                                      1.0]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=1001, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(train_features,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.801829198055613"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "Precision: 0.8108108108108109\n",
      "Recall: 0.9230769230769231\n",
      "F1-score: 0.8633093525179857\n",
      "AUC-ROC: 0.7282051282051282\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_label,predicted.argmax(axis=1)))\n",
    "print(\"Precision:\",metrics.precision_score(test_label,predicted.argmax(axis=1)))\n",
    "print(\"Recall:\",metrics.recall_score(test_label,predicted.argmax(axis=1)))\n",
    "print(\"F1-score:\",metrics.f1_score(test_label,predicted.argmax(axis=1)))\n",
    "print(\"AUC-ROC:\",metrics.roc_auc_score(test_label,predicted.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marina/.local/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                     batch_size='auto', beta_1=0.9,\n",
       "                                     beta_2=0.999, early_stopping=False,\n",
       "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
       "                                     learning_rate='constant',\n",
       "                                     learning_rate_init=0.001, max_fun=15000,\n",
       "                                     max_iter=100, momentum=0.9,\n",
       "                                     n_iter_no_change=10,\n",
       "                                     nesterovs_momentum=True, power_t=0.5,\n",
       "                                     random_state...\n",
       "                                     validation_fraction=0.1, verbose=False,\n",
       "                                     warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'activation': ['tanh', 'relu'],\n",
       "                         'alpha': [0.0001, 0.05],\n",
       "                         'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50),\n",
       "                                                (100,)],\n",
       "                         'learning_rate': ['constant', 'adaptive'],\n",
       "                         'solver': ['sgd', 'adam']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3, scoring='roc_auc')\n",
    "clf.fit(train_features, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6194162231898082"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.546 (+/-0.017) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.606 (+/-0.133) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.564 (+/-0.112) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.570 (+/-0.182) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.587 (+/-0.036) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.547 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.579 (+/-0.092) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.619 (+/-0.169) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.546 (+/-0.020) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.594 (+/-0.048) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.591 (+/-0.199) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.560 (+/-0.033) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.515 (+/-0.098) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.553 (+/-0.141) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.556 (+/-0.205) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.577 (+/-0.060) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.507 (+/-0.050) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.557 (+/-0.034) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.529 (+/-0.050) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.495 (+/-0.111) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.519 (+/-0.062) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.579 (+/-0.070) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.539 (+/-0.120) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.572 (+/-0.062) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.551 (+/-0.287) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.542 (+/-0.039) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.508 (+/-0.186) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.537 (+/-0.172) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.519 (+/-0.185) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.475 (+/-0.149) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.521 (+/-0.209) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.571 (+/-0.109) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.539 (+/-0.178) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.513 (+/-0.230) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.515 (+/-0.213) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.616 (+/-0.111) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.521 (+/-0.197) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.565 (+/-0.043) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.552 (+/-0.222) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.525 (+/-0.230) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.600 (+/-0.218) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.480 (+/-0.124) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.591 (+/-0.275) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.615 (+/-0.010) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.460 (+/-0.119) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.546 (+/-0.058) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.544 (+/-0.169) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.578 (+/-0.301) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Best paramete set\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "\n",
    "# All results\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7052631578947368\n",
      "Precision: 0.7078651685393258\n",
      "Recall: 0.9692307692307692\n",
      "F1-score: 0.8181818181818182\n",
      "AUC-ROC: 0.5512820512820513\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_label,predicted))\n",
    "print(\"Precision:\",metrics.precision_score(test_label,predicted))\n",
    "print(\"Recall:\",metrics.recall_score(test_label,predicted))\n",
    "print(\"F1-score:\",metrics.f1_score(test_label,predicted))\n",
    "print(\"AUC-ROC:\",metrics.roc_auc_score(test_label,predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
